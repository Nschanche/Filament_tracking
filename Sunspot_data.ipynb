{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from StringIO import StringIO\n",
    "import csv\n",
    "import requests\n",
    "import requests_cache\n",
    "import tarfile\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Begin</th>\n",
       "      <th>Max</th>\n",
       "      <th>End</th>\n",
       "      <th>Obs</th>\n",
       "      <th>Q</th>\n",
       "      <th>Type</th>\n",
       "      <th>Loc/Frq</th>\n",
       "      <th>Particulars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 180</td>\n",
       "      <td>  557</td>\n",
       "      <td>  557</td>\n",
       "      <td>  557</td>\n",
       "      <td> LEA</td>\n",
       "      <td> G</td>\n",
       "      <td> RBR</td>\n",
       "      <td>    410</td>\n",
       "      <td>               200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 190</td>\n",
       "      <td> 1203</td>\n",
       "      <td> 1209</td>\n",
       "      <td> 1214</td>\n",
       "      <td> G15</td>\n",
       "      <td> 5</td>\n",
       "      <td> XRA</td>\n",
       "      <td>   1-8A</td>\n",
       "      <td> B6.3 3.0E-04 1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 200</td>\n",
       "      <td> 1927</td>\n",
       "      <td> 1933</td>\n",
       "      <td> 1939</td>\n",
       "      <td> G15</td>\n",
       "      <td> 5</td>\n",
       "      <td> XRA</td>\n",
       "      <td>   1-8A</td>\n",
       "      <td> C1.5 7.3E-04 1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 200</td>\n",
       "      <td> 1929</td>\n",
       "      <td> 1931</td>\n",
       "      <td> 1940</td>\n",
       "      <td> HOL</td>\n",
       "      <td> 3</td>\n",
       "      <td> FLA</td>\n",
       "      <td> N12E51</td>\n",
       "      <td>       SF ERU 1638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event  Begin   Max   End  Obs  Q Type Loc/Frq        Particulars\n",
       "0    180    557   557   557  LEA  G  RBR     410                200\n",
       "1    190   1203  1209  1214  G15  5  XRA    1-8A  B6.3 3.0E-04 1638\n",
       "2    200   1927  1933  1939  G15  5  XRA    1-8A  C1.5 7.3E-04 1638\n",
       "3    200   1929  1931  1940  HOL  3  FLA  N12E51        SF ERU 1638"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SWPC's events for a given day are stored in a separate file, and all the files\n",
    "# for the year 2013 are in a compressed archive. Each of the files looks like \n",
    "# the one below.\n",
    "\n",
    "test_str = \"\"\"\n",
    ":Product: 20121229events.txt\n",
    ":Created: 2013 Jan 01 0332 UT\n",
    ":Date: 2012 12 29\n",
    "# Prepared by the U.S. Dept. of Commerce, NOAA, Space Weather Prediction Center\n",
    "# Please send comments and suggestions to SWPC.Webmaster@noaa.gov \n",
    "#\n",
    "# Missing data: ////\n",
    "# Updated every 30 minutes.\n",
    "#                            Edited Events for 2012 Dec 29\n",
    "#\n",
    "#Event    Begin    Max       End  Obs  Q  Type  Loc/Frq   Particulars       Reg#\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    " 180       0557   0557      0557  LEA  G   RBR  410       200                   \n",
    "\n",
    " 190       1203   1209      1214  G15  5   XRA  1-8A      B6.3    3.0E-04   1638\n",
    "\n",
    " 200       1927   1933      1939  G15  5   XRA  1-8A      C1.5    7.3E-04   1638\n",
    " 200       1929   1931      1940  HOL  3   FLA  N12E51    SF      ERU       1638\n",
    "\"\"\"\n",
    "\n",
    "# Note that the separators in the above file are spaces, not tabs. We will\n",
    "# therefore need to develop functionality that converts files like these into\n",
    "# a format that can be recognized by pandas.\n",
    "\n",
    "def split_and_purge(in_str, delim=None, purge=[\"\", \"+\"]):\n",
    "    \"\"\"Splits a string into an array of strings, removing unwanted strings.\"\"\"\n",
    "    pieces = []\n",
    "    if delim is None:\n",
    "        pieces = in_str.split()  # Split for both spaces and tabs.\n",
    "    else:\n",
    "        pieces = in_str.split(delim)\n",
    "    return [piece for piece in pieces if piece not in purge]\n",
    "\n",
    "def parse_events(events_file):\n",
    "    \"\"\"Parses an swpc events file into a pandas-friendly form.\"\"\"\n",
    "    # Split into lines.\n",
    "    lines = split_and_purge(events_file, delim=\"\\n\")\n",
    "    \n",
    "    # Throw away the first 10 lines. We do not need the info contained therein.\n",
    "    lines = lines[10:]\n",
    "\n",
    "    if len(lines) < 2:\n",
    "        return \"\"\n",
    "\n",
    "    # Get the column titles. Clean them.\n",
    "    title_row = split_and_purge(lines[0])\n",
    "    title_row = [title.replace(\"#\", \"\") for title in title_row]\n",
    "    \n",
    "    # We merge the Particulars and Reg columns since these are sometimes left\n",
    "    # blank. The other fields do not seem to have blank values (based on\n",
    "    # spot-checking).\n",
    "    title_row = title_row[:-1]\n",
    "    \n",
    "    # Get the rows.\n",
    "    rows = []\n",
    "    for line in lines[2:]:\n",
    "        items = split_and_purge(line)\n",
    "        \n",
    "        # Too few items.\n",
    "        if len(items) < 8:\n",
    "            continue\n",
    "        \n",
    "        # Take the first 8 columns as distinct items. Remaining items are\n",
    "        # thrown together into a single column.\n",
    "        rows.append(items[:8] + [\" \".join(items[8:])])\n",
    "\n",
    "    # Create csv.\n",
    "    strio = StringIO()\n",
    "    writer = csv.writer(strio)\n",
    "    writer.writerows([title_row] + rows)\n",
    "    return strio.getvalue()\n",
    "\n",
    "# Test the function above.\n",
    "pd.read_csv(StringIO(parse_events(test_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringIO.StringIO instance at 0x1078b97e8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Begin</th>\n",
       "      <th>Max</th>\n",
       "      <th>End</th>\n",
       "      <th>Obs</th>\n",
       "      <th>Q</th>\n",
       "      <th>Type</th>\n",
       "      <th>Loc/Frq</th>\n",
       "      <th>Particulars</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 3710</td>\n",
       "      <td>   0</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> 1052</td>\n",
       "      <td> LEA</td>\n",
       "      <td> C</td>\n",
       "      <td> RSP</td>\n",
       "      <td> 031-180</td>\n",
       "      <td>             CTM/1</td>\n",
       "      <td> 20111229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 3600</td>\n",
       "      <td> 316</td>\n",
       "      <td> 0319</td>\n",
       "      <td>  326</td>\n",
       "      <td> G15</td>\n",
       "      <td> 5</td>\n",
       "      <td> XRA</td>\n",
       "      <td>    1-8A</td>\n",
       "      <td>      C1.2 5.6E-04</td>\n",
       "      <td> 20111229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 3600</td>\n",
       "      <td> 323</td>\n",
       "      <td>  NaN</td>\n",
       "      <td>  737</td>\n",
       "      <td> LEA</td>\n",
       "      <td> C</td>\n",
       "      <td> RSP</td>\n",
       "      <td> 025-180</td>\n",
       "      <td>              VI/2</td>\n",
       "      <td> 20111229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 3610</td>\n",
       "      <td> 358</td>\n",
       "      <td> 0405</td>\n",
       "      <td>  411</td>\n",
       "      <td> G15</td>\n",
       "      <td> 5</td>\n",
       "      <td> XRA</td>\n",
       "      <td>    1-8A</td>\n",
       "      <td> C3.0 1.4E-03 1389</td>\n",
       "      <td> 20111229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 3610</td>\n",
       "      <td> 404</td>\n",
       "      <td> 0405</td>\n",
       "      <td>  409</td>\n",
       "      <td> LEA</td>\n",
       "      <td> 3</td>\n",
       "      <td> FLA</td>\n",
       "      <td>  S26E72</td>\n",
       "      <td>           SF 1389</td>\n",
       "      <td> 20111229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event Begin   Max   End  Obs  Q Type  Loc/Frq        Particulars      Date\n",
       "0   3710     0   NaN  1052  LEA  C  RSP  031-180              CTM/1  20111229\n",
       "1   3600   316  0319   326  G15  5  XRA     1-8A       C1.2 5.6E-04  20111229\n",
       "2   3600   323   NaN   737  LEA  C  RSP  025-180               VI/2  20111229\n",
       "3   3610   358  0405   411  G15  5  XRA     1-8A  C3.0 1.4E-03 1389  20111229\n",
       "4   3610   404  0405   409  LEA  3  FLA   S26E72            SF 1389  20111229"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We proceed to read in all SWPC events for the year 2012 into a dataframe.\n",
    "import re\n",
    "#SWPC_2012_URL = \"http://legacy-www.swpc.noaa.gov/ftpdir/warehouse/2012/2012_events.tar.gz\"\n",
    "SWPC_2012_URL = '/Users/nschanch/Downloads/2012_events.tar.gz'\n",
    "#strio = StringIO(requests.get(SWPC_2012_URL).content)\n",
    "#strio = StringIO(SWPC_2012_URL)\n",
    "#tarred = tarfile.AREGTYPEopen(\"r:gz\", fileobj=strio)\n",
    "tarred = tarfile.open(SWPC_2012_URL)\n",
    "print strio\n",
    "swpc_by_day = []\n",
    "for tarinfo in tarred:\n",
    "    if not tarinfo.isdir():\n",
    "        extracted = tarred.extractfile(tarinfo).read()\n",
    "        day = re.match(r\"^2012_events/(\\d+)events.txt\", tarinfo.name).group(1)\n",
    "        df = pd.read_csv(StringIO(parse_events(extracted)))\n",
    "        df[\"Date\"] = [day] * len(df)\n",
    "        swpc_by_day.append(df)\n",
    "\n",
    "# Form a single dataframe. Replace '////'\n",
    "swpc = pd.concat(swpc_by_day)\n",
    "for col in list(swpc.columns):\n",
    "    swpc[col] = swpc[col].apply(lambda x: np.nan if \"////\" in str(x) else x)\n",
    "\n",
    "swpc.sort([\"Date\", \"Begin\"], ascending=[1, 1], inplace=True)\n",
    "swpc.reset_index(drop=True, inplace=True)\n",
    "swpc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nmbr</th>\n",
       "      <th>Location</th>\n",
       "      <th>Lo</th>\n",
       "      <th>Area</th>\n",
       "      <th>Z</th>\n",
       "      <th>LL</th>\n",
       "      <th>NN</th>\n",
       "      <th>Mag Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td> 1638</td>\n",
       "      <td> N13W34</td>\n",
       "      <td> 308</td>\n",
       "      <td>  80</td>\n",
       "      <td> Hsx</td>\n",
       "      <td>  2</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td> 1640</td>\n",
       "      <td> N28W48</td>\n",
       "      <td> 322</td>\n",
       "      <td> 320</td>\n",
       "      <td> Eki</td>\n",
       "      <td> 13</td>\n",
       "      <td> 24</td>\n",
       "      <td> Beta-Gamma-Delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> 1641</td>\n",
       "      <td> N04W05</td>\n",
       "      <td> 279</td>\n",
       "      <td>  40</td>\n",
       "      <td> Cao</td>\n",
       "      <td>  8</td>\n",
       "      <td>  2</td>\n",
       "      <td>             Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td> 1642</td>\n",
       "      <td> S24E22</td>\n",
       "      <td> 252</td>\n",
       "      <td> 100</td>\n",
       "      <td> Hsx</td>\n",
       "      <td>  2</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td> 1644</td>\n",
       "      <td> N15E35</td>\n",
       "      <td> 239</td>\n",
       "      <td>  40</td>\n",
       "      <td> Hsx</td>\n",
       "      <td>  2</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> 1645</td>\n",
       "      <td> S13W18</td>\n",
       "      <td> 292</td>\n",
       "      <td>  50</td>\n",
       "      <td> Dao</td>\n",
       "      <td>  5</td>\n",
       "      <td>  8</td>\n",
       "      <td>             Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> 1646</td>\n",
       "      <td> N14E45</td>\n",
       "      <td> 229</td>\n",
       "      <td>  30</td>\n",
       "      <td> Hax</td>\n",
       "      <td>  1</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td> 1647</td>\n",
       "      <td> N16W55</td>\n",
       "      <td> 329</td>\n",
       "      <td>  30</td>\n",
       "      <td> Cao</td>\n",
       "      <td>  5</td>\n",
       "      <td>  4</td>\n",
       "      <td>             Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> 1648</td>\n",
       "      <td> N05E53</td>\n",
       "      <td> 221</td>\n",
       "      <td>  20</td>\n",
       "      <td> Cro</td>\n",
       "      <td>  3</td>\n",
       "      <td>  2</td>\n",
       "      <td>             Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 1649</td>\n",
       "      <td> S14E74</td>\n",
       "      <td> 200</td>\n",
       "      <td>  60</td>\n",
       "      <td> Hsx</td>\n",
       "      <td>  2</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 1650</td>\n",
       "      <td> S26E77</td>\n",
       "      <td> 197</td>\n",
       "      <td>  50</td>\n",
       "      <td> Hsx</td>\n",
       "      <td>  2</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 1651</td>\n",
       "      <td> N19E48</td>\n",
       "      <td> 225</td>\n",
       "      <td>  10</td>\n",
       "      <td> Axx</td>\n",
       "      <td>  1</td>\n",
       "      <td>  1</td>\n",
       "      <td>            Alpha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nmbr Location   Lo  Area    Z  LL  NN          Mag Type\n",
       "0   1638   N13W34  308    80  Hsx   2   1             Alpha\n",
       "1   1640   N28W48  322   320  Eki  13  24  Beta-Gamma-Delta\n",
       "2   1641   N04W05  279    40  Cao   8   2              Beta\n",
       "3   1642   S24E22  252   100  Hsx   2   1             Alpha\n",
       "4   1644   N15E35  239    40  Hsx   2   1             Alpha\n",
       "5   1645   S13W18  292    50  Dao   5   8              Beta\n",
       "6   1646   N14E45  229    30  Hax   1   1             Alpha\n",
       "7   1647   N16W55  329    30  Cao   5   4              Beta\n",
       "8   1648   N05E53  221    20  Cro   3   2              Beta\n",
       "9   1649   S14E74  200    60  Hsx   2   1             Alpha\n",
       "10  1650   S26E77  197    50  Hsx   2   1             Alpha\n",
       "11  1651   N19E48  225    10  Axx   1   1             Alpha"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we read SWPC Sunspot Data, similarly to above.\n",
    "\n",
    "sunspot_test = \"\"\"\n",
    ":Product: 0105SRS.txt\n",
    ":Issued: 2013 Jan 05 0030 UTC\n",
    "# Prepared jointly by the U.S. Dept. of Commerce, NOAA,\n",
    "# Space Weather Prediction Center and the U.S. Air Force.\n",
    "#\n",
    "Joint USAF/NOAA Solar Region Summary\n",
    "SRS Number 5 Issued at 0030Z on 05 Jan 2013\n",
    "Report compiled from data received at SWO on 04 Jan\n",
    "I.  Regions with Sunspots.  Locations Valid at 04/2400Z \n",
    "Nmbr Location  Lo  Area  Z   LL   NN Mag Type\n",
    "1638 N13W34   308  0080 Hsx  02   01 Alpha\n",
    "1640 N28W48   322  0320 Eki  13   24 Beta-Gamma-Delta\n",
    "1641 N04W05   279  0040 Cao  08   02 Beta\n",
    "1642 S24E22   252  0100 Hsx  02   01 Alpha\n",
    "1644 N15E35   239  0040 Hsx  02   01 Alpha\n",
    "1645 S13W18   292  0050 Dao  05   08 Beta\n",
    "1646 N14E45   229  0030 Hax  01   01 Alpha\n",
    "1647 N16W55   329  0030 Cao  05   04 Beta\n",
    "1648 N05E53   221  0020 Cro  03   02 Beta\n",
    "1649 S14E74   200  0060 Hsx  02   01 Alpha\n",
    "1650 S26E77   197  0050 Hsx  02   01 Alpha\n",
    "1651 N19E48   225  0010 Axx  01   01 Alpha\n",
    "IA. H-alpha Plages without Spots.  Locations Valid at 04/2400Z Jan\n",
    "Nmbr  Location  Lo\n",
    "1636  N14W69   343\n",
    "1637  N06W77   351\n",
    "1639  S16W38   312\n",
    "1643  S14E17   257\n",
    "II. Regions Due to Return 05 Jan to 07 Jan\n",
    "Nmbr Lat    Lo\n",
    "None\n",
    "\"\"\"\n",
    "\n",
    "# Numpy returns NotImplemented when you try to compare lists of\n",
    "# strings for equality. This is just insane. We provide here an\n",
    "# alternative for all(np.equal(a, b))\n",
    "def are_equal(list_a, list_b):\n",
    "    if len(list_a) != len(list_b):\n",
    "        return False\n",
    "    return all([a == b for a, b in zip(list_a, list_b)])\n",
    "\n",
    "\n",
    "sunspot_title_row = ['Nmbr', 'Location', 'Lo', 'Area', 'Z', 'LL', 'NN', 'Mag', 'Type']\n",
    "\n",
    "def parse_sunspot(sunspot_file):\n",
    "    \"\"\"Parses a swpc sunspot file into a pandas-friendly form.\"\"\"\n",
    "    # Split into lines.\n",
    "    lines = split_and_purge(sunspot_file, \"\\n\")\n",
    "\n",
    "    # Look for the first row that has 9 words. This is the title row.\n",
    "    i = -1\n",
    "    title_row = None\n",
    "    for line in lines:\n",
    "        i += 1\n",
    "        if are_equal(sunspot_title_row, split_and_purge(line)):\n",
    "            title_row = sunspot_title_row\n",
    "            title_row = title_row[:7] + [\" \".join(title_row[7:])]\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if title_row is None:\n",
    "        return \"\"\n",
    "\n",
    "    # Get the rows.\n",
    "    rows = []\n",
    "    for line in lines[i + 1:]:\n",
    "        items = split_and_purge(line)\n",
    "\n",
    "        # We are done retrieving the rows we need.\n",
    "        if len(items) != 8:\n",
    "            break\n",
    "\n",
    "        rows.append(items)\n",
    "\n",
    "    # Create csv.\n",
    "    strio = StringIO()\n",
    "    writer = csv.writer(strio)\n",
    "    writer.writerows([title_row] + rows)\n",
    "    return strio.getvalue()\n",
    "\n",
    "# Test the function above.\n",
    "pd.read_csv(StringIO(parse_sunspot(sunspot_test))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-24860abd5977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Get spots for year 2012.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0msunspot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sunspots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2012\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0msunspot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-24860abd5977>\u001b[0m in \u001b[0;36mget_sunspots\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# The tar members are named like '2010_SRS/20100420SRS.txt'. We use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# a regex to extract the day.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^.*?SRS/(\\d+)SRS.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_sunspot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "def get_sunspots(year) :\n",
    "    \"\"\"Returns a dataframe containing sunspot data for a given year.\"\"\"\n",
    "    today = np.datetime64(datetime.now())\n",
    "\n",
    "    # Parse every file for the given year into a dataframe, then add the df\n",
    "    # to a list.\n",
    "    sunspot_by_day = []\n",
    "    \n",
    "    # The files are placed into an archive after the year ends. Before that,\n",
    "    # they are uncompressed.\n",
    "    if today.item().year == year:\n",
    "        # Since it takes about a minute to scrape all the text files individually for\n",
    "        # a given year, we save the parsed content locally as a tarfile, and load it up\n",
    "        # when we want the data again.\n",
    "        \n",
    "        local_tar_path = os.path.join(os.getcwd(), \"%d_SRS.tar.gz\" % year)\n",
    "        if os.path.exists(local_tar_path):  # Archive exists from recent save.\n",
    "            tarred = tarfile.open(local_tar_path, \"r:gz\")\n",
    "            for tarinfo in tarred:\n",
    "                if tarinfo.isdir():\n",
    "                    continue\n",
    "                extracted = tarred.extractfile(tarinfo).read()\n",
    "\n",
    "                # The tar members are named like '20100420SRS.txt'. We use\n",
    "                # a regex to extract the day.\n",
    "                day = re.match(r\"^(\\d+).txt\", tarinfo.name).group(1)\n",
    "\n",
    "                df = pd.read_csv(StringIO(extracted))\n",
    "                df[\"Date\"] = [day] * len(df)\n",
    "                sunspot_by_day.append(df)\n",
    "            tarred.close()\n",
    "        else:  # Archive does not exists, so download files and add them to the archive.\n",
    "            tarred = tarfile.open(local_tar_path, \"w:gz\")\n",
    "            urlformat = \"http://legacy-www.swpc.noaa.gov/ftpdir/warehouse/%d/SRS/%sSRS.txt\"\n",
    "            urlformat = '/Users/nschanch/Downloads/%s_SRS/%sSRS.txt'\n",
    "            curr_date = np.datetime64(str(year))\n",
    "            while curr_date < today:\n",
    "                date_str = curr_date.item().strftime(\"%Y%m%d\")\n",
    "                curr_url = urlformat % (year, date_str)\n",
    "                strio = StringIO(parse_sunspot(requests.get(curr_url).content))\n",
    "                df = pd.read_csv(strio)\n",
    "                df[\"Date\"] = [date_str] * len(df)\n",
    "                sunspot_by_day.append(df)\n",
    "                info = tarred.tarinfo()\n",
    "                info.name = \"%s.txt\" % date_str\n",
    "                info.size = strio.len\n",
    "                strio.seek(0)  # Reset file position.\n",
    "                tarred.addfile(info, fileobj=strio)\n",
    "                curr_date += np.timedelta64(1, \"D\")\n",
    "            tarred.close()\n",
    "    else:\n",
    "        # The prefix for the archive file for 2006 is different from the other years.\n",
    "        file_pref = \"\" if year == 2006 or year == 2007 else \"%s_\" % year\n",
    "\n",
    "        #The swpc changed their website during the course of this project.  The data will still be\n",
    "        #available at this legacy site for 60 days. After this we would need to find a new url.  \n",
    "        #SUNSPOT_URL = \"http://legacy-www.swpc.noaa.gov/ftpdir/warehouse/%s/%sSRS.tar.gz\" % (year, file_pref)\n",
    "        SUNSPOT_URL = '/Users/nschanch/Downloads/2012_SRS.tar.gz'\n",
    "        #strio = StringIO(requests.get(SUNSPOT_URL).content)\n",
    "        tarred = tarfile.open(SUNSPOT_URL)\n",
    "\n",
    "        # Parse every file for the given year into a dataframe, then add the df\n",
    "        # to a list.\n",
    "        for tarinfo in tarred:\n",
    "            if tarinfo.isdir():\n",
    "                continue\n",
    "            \n",
    "            extracted = tarred.extractfile(tarinfo).read()\n",
    "\n",
    "            # The tar members are named like '2010_SRS/20100420SRS.txt'. We use\n",
    "            # a regex to extract the day.\n",
    "            day = re.match(r\"^.*?SRS/(\\d+)SRS.txt\", tarinfo.name).group(1)\n",
    "\n",
    "            df = pd.read_csv(StringIO(parse_sunspot(extracted)))\n",
    "            df[\"Date\"] = [day] * len(df)\n",
    "            sunspot_by_day.append(df)\n",
    "        tarred.close()\n",
    "\n",
    "    # Form a single dataframe.\n",
    "    sunspot = pd.concat(sunspot_by_day)\n",
    "    sunspot.sort([\"Date\", \"Nmbr\"], ascending=[1, 1], inplace=True)\n",
    "    sunspot.reset_index(drop=True, inplace=True)\n",
    "    return sunspot\n",
    "\n",
    "# Get spots for year 2012.\n",
    "sunspot = get_sunspots(2012)\n",
    "sunspot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
